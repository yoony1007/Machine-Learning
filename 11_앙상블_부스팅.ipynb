{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting(부스팅)\n",
    "- 단순하고 약한 학습기(Weak Learner)들 결합해, 정확하고 강력한 학습기(Strong Learner) 만드는 방식  \n",
    "- 정확도가 낮은 하나의 모델을 만들어 학습시킨 뒤, 그 모델의 예측 오류는 두 번째 모델이 보완하는 방식\n",
    "- 이 두 모델을 합치면 처음보다는 정확한 모델 만들어지며, 합쳐진 모델의 예측 오류는 다음 모델에서 보완하여 계속 더하는 과정 반복\n",
    "- 약한 학습기들은 앞 학습기가 만든 오류 줄이는 방향으로 학습\n",
    "- vs Voting\n",
    "    - Voting 방식의 경우, 각 모델이 독립적(개별적)으로 학습\n",
    "    - 각 모델의 결과를 취합해 최종 결과 산출\n",
    "    - 병렬적으로 일할 수 있음\n",
    "- gradient boosting(PDF 참고)\n",
    "    - 처음 모델은 y 예측 -> 두번째 모델부터는 앞 모델이 만든 오류(실제 값 - 예측 값) 예측 -> 그것을 앞 모델에 업데이트하면 오류 줄일 수 있음\n",
    "    - 오류를 update 할 때, 뺄지 더할지를 결정할 때, gradient descent 방법 사용. 미분해서 나오는 값의 음수를 취해서 적용 \n",
    "    - 학습률(Learning Rate)을 작게 하면 update를 조금씩, 크면 많이 하게 됨. 크게하면 학습데이터에 너무 맞아 과대적합 될 수 있음\n",
    "\n",
    "## GradientBoosting\n",
    "- 대용량 데이터일 때, 성능이 좋음\n",
    "- 개별 모델로 Decision Tree 사용\n",
    "- depth가 깊지 않은 트리를 많이 연결해, 이전 트리의 오차를 보정해 나가는 방식\n",
    "    - 성능이 좋은 모델을 사용하면, 오히려 과대적합 날 수 있음\n",
    "- 오차를 보정할 때 경사하강법(Gradient descent) 사용(미분)\n",
    "- 얕은 트리를 많이 연결해, 각 트리가 데이터 일부에 대해 예측 잘 수행하도록 하고 그런 트리들이 모여 전체 성능 높이는 형태\n",
    "- 분류와 회귀 둘다 지원하는 모델 (GradientBoostingClassification, GrandientBoostingRegressor)\n",
    "- 훈련시간 많이 걸리고, 트리기반 모델의 특성상 희소한 고차원 데이터에서는 성능 좋지 않은 단점\n",
    "    - 희소한 고차원 데이터? 값에 0이 많은, 컬럼이 많은 데이터 => 고차원의 희소행렬\n",
    "\n",
    "### 주요 파라미터\n",
    "- Decision Tree의 가지치기 관련 매개변수\n",
    "    - 각각 tree가 복잡한 모델이 되지 않도록 함\n",
    "- learning rate\n",
    "    - 이전 tree의 오차를 얼마나 강하게 보정할 것인지 제어하는 값\n",
    "    - 값이 크면 보정 강하게 해 복잡한 모델 만듬. 학습데이터 정확도는 올라가지만 과대적합 날 수 있음 \n",
    "    - 값을 작게 잡으면 보정 약하게 하여 모델 복잡도 줄임. 과대적합을 줄일 수 있지만 성능 자체가 낮아질 수 있음\n",
    "    - 기본값 : 0.1, 0.01에서 보통 시작해 늘리거나, 줄여나가는 형식\n",
    "- n_estimators\n",
    "    - tree 개수 지정. 많을수록 복잡한 모델됨\n",
    "    - Learning rate와 관련(반비례)\n",
    "        - Learning rate를 크게 주면 -> n_estimators는 작게\n",
    "        - Learning rate를 작게 주면 -> n_estimators는 크게\n",
    "- n_iter_no_change(정수), validation_fraction(비율)\n",
    "    - validation_fraction에 지정한 비율만큼 n_iter_no_change에 지정한 반복 횟수동안 검증점수가 좋아지지 않으면 훈련을 조기 종료(early stopping\n",
    "        - validation_fraction을 0.1, n_iter_no_change = 5, n_estimators = 1000인 상황. 오차 찾는 과정에서 tree 300개로 이미 오차 다 찾음. 나멎 700개 트리는 오차가 없어서 할 일이 없음. 300개에서 끊어버리면 됨  \n",
    "        - validation_fraction: 학습률의 증가치. 5개 모델 학습하는데 성능 높아지는 비율(오차 줄어드는 비율)이 10% 이상 증가하지 않으면 트리가 더 남아있다고 하더라도 더 이상 학습하지 말고 정지\n",
    "\n",
    "- 보통 max_depth 낮춰 개별 트리 복잡도 낮춤(5가 넘지 않게). 그리고 n_estimators를 가용시간, 메모리 한도에 맞춘 뒤, 적절한 learning_rate 찾음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((426,), (143,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_breast_cancer()\n",
    "X, y = data['data'], data['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, random_state = 1)\n",
    "# GradientBoosting 하기에는 데이터 양 적은 편 -> 복잡한 모델이기 때문에 과적합 날 가능성 높음\n",
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GradientBoosting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(random_state = 1)\n",
    "gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = gb.predict(X_train)\n",
    "pred_test = gb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_train, pred_train), accuracy_score(y_test, pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature 중요도\n",
    "import pandas as pd\n",
    "fi = gb.feature_importances_\n",
    "fi_s = pd.Series(fi, index = data['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "worst radius               0.383760\n",
       "worst concave points       0.285992\n",
       "worst perimeter            0.130660\n",
       "mean concave points        0.046544\n",
       "worst area                 0.042472\n",
       "worst texture              0.041142\n",
       "worst concavity            0.013033\n",
       "area error                 0.010910\n",
       "mean texture               0.009101\n",
       "mean concavity             0.007719\n",
       "radius error               0.004902\n",
       "concavity error            0.003397\n",
       "worst fractal dimension    0.002838\n",
       "mean area                  0.002552\n",
       "worst symmetry             0.002546\n",
       "fractal dimension error    0.002532\n",
       "mean compactness           0.001566\n",
       "compactness error          0.001386\n",
       "mean perimeter             0.001368\n",
       "smoothness error           0.001340\n",
       "symmetry error             0.001265\n",
       "perimeter error            0.000813\n",
       "mean radius                0.000701\n",
       "mean fractal dimension     0.000625\n",
       "texture error              0.000498\n",
       "worst smoothness           0.000144\n",
       "worst compactness          0.000097\n",
       "mean smoothness            0.000051\n",
       "mean symmetry              0.000039\n",
       "concave points error       0.000008\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi_s.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV 이용해 최적의 하이퍼파라미터 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "param = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],  # tree개수(default: 100)\n",
    "    'learning_rate': [0.001, 0.005, 0.01, 0.5, 0.1],  # 학습률\n",
    "    'max_depth': range(1, 5),\n",
    "    'subsample': [0.5, 0.7, 1],  # 학습시킬 sample의 비율\n",
    "}\n",
    "gb = GradientBoostingClassifier(random_state = 1)\n",
    "\n",
    "gs = GridSearchCV(gb,\n",
    "                  param_grid = param,\n",
    "                  cv = 3,\n",
    "                  scoring = 'accuracy',\n",
    "                  n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=GradientBoostingClassifier(random_state=1),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.001, 0.005, 0.01, 0.5, 0.1],\n",
       "                         'max_depth': range(1, 5),\n",
       "                         'n_estimators': [100, 200, 300, 400, 500],\n",
       "                         'subsample': [0.5, 0.7, 1]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.5, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.5}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>1.249222</td>\n",
       "      <td>0.013107</td>\n",
       "      <td>0.002982</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>0.974178</td>\n",
       "      <td>0.008783</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.377336</td>\n",
       "      <td>0.024049</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.978873</td>\n",
       "      <td>0.978873</td>\n",
       "      <td>0.974178</td>\n",
       "      <td>0.006640</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>1.562981</td>\n",
       "      <td>0.013348</td>\n",
       "      <td>0.002830</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.5, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.978873</td>\n",
       "      <td>0.978873</td>\n",
       "      <td>0.974178</td>\n",
       "      <td>0.006640</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>1.402380</td>\n",
       "      <td>0.052528</td>\n",
       "      <td>0.002329</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.992958</td>\n",
       "      <td>0.974178</td>\n",
       "      <td>0.014470</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>1.292763</td>\n",
       "      <td>0.050067</td>\n",
       "      <td>0.002328</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 4, 'n_esti...</td>\n",
       "      <td>0.964789</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>0.974178</td>\n",
       "      <td>0.008783</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.812115</td>\n",
       "      <td>0.051518</td>\n",
       "      <td>0.001836</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 2, 'n_es...</td>\n",
       "      <td>0.626761</td>\n",
       "      <td>0.626761</td>\n",
       "      <td>0.626761</td>\n",
       "      <td>0.626761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.626055</td>\n",
       "      <td>0.120975</td>\n",
       "      <td>0.002327</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 4, 'n_es...</td>\n",
       "      <td>0.626761</td>\n",
       "      <td>0.626761</td>\n",
       "      <td>0.626761</td>\n",
       "      <td>0.626761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.887718</td>\n",
       "      <td>0.015895</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 2, 'n_es...</td>\n",
       "      <td>0.626761</td>\n",
       "      <td>0.626761</td>\n",
       "      <td>0.626761</td>\n",
       "      <td>0.626761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.008480</td>\n",
       "      <td>0.024664</td>\n",
       "      <td>0.002327</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 4, 'n_es...</td>\n",
       "      <td>0.626761</td>\n",
       "      <td>0.626761</td>\n",
       "      <td>0.626761</td>\n",
       "      <td>0.626761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.225744</td>\n",
       "      <td>0.009665</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 1, 'n_es...</td>\n",
       "      <td>0.626761</td>\n",
       "      <td>0.626761</td>\n",
       "      <td>0.626761</td>\n",
       "      <td>0.626761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "215       1.249222      0.013107         0.002982        0.000816   \n",
       "195       0.377336      0.024049         0.001508        0.000722   \n",
       "207       1.562981      0.013348         0.002830        0.000229   \n",
       "263       1.402380      0.052528         0.002329        0.000471   \n",
       "289       1.292763      0.050067         0.002328        0.000470   \n",
       "..             ...           ...              ...             ...   \n",
       "19        0.812115      0.051518         0.001836        0.000224   \n",
       "45        0.626055      0.120975         0.002327        0.000470   \n",
       "17        0.887718      0.015895         0.001663        0.000470   \n",
       "48        1.008480      0.024664         0.002327        0.000471   \n",
       "0         0.225744      0.009665         0.001657        0.000478   \n",
       "\n",
       "    param_learning_rate param_max_depth param_n_estimators param_subsample  \\\n",
       "215                 0.5               3                200               1   \n",
       "195                 0.5               2                100             0.5   \n",
       "207                 0.5               2                500             0.5   \n",
       "263                 0.1               2                300               1   \n",
       "289                 0.1               4                200             0.7   \n",
       "..                  ...             ...                ...             ...   \n",
       "19                0.001               2                200             0.7   \n",
       "45                0.001               4                100             0.5   \n",
       "17                0.001               2                100               1   \n",
       "48                0.001               4                200             0.5   \n",
       "0                 0.001               1                100             0.5   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "215  {'learning_rate': 0.5, 'max_depth': 3, 'n_esti...           0.964789   \n",
       "195  {'learning_rate': 0.5, 'max_depth': 2, 'n_esti...           0.964789   \n",
       "207  {'learning_rate': 0.5, 'max_depth': 2, 'n_esti...           0.964789   \n",
       "263  {'learning_rate': 0.1, 'max_depth': 2, 'n_esti...           0.957746   \n",
       "289  {'learning_rate': 0.1, 'max_depth': 4, 'n_esti...           0.964789   \n",
       "..                                                 ...                ...   \n",
       "19   {'learning_rate': 0.001, 'max_depth': 2, 'n_es...           0.626761   \n",
       "45   {'learning_rate': 0.001, 'max_depth': 4, 'n_es...           0.626761   \n",
       "17   {'learning_rate': 0.001, 'max_depth': 2, 'n_es...           0.626761   \n",
       "48   {'learning_rate': 0.001, 'max_depth': 4, 'n_es...           0.626761   \n",
       "0    {'learning_rate': 0.001, 'max_depth': 1, 'n_es...           0.626761   \n",
       "\n",
       "     split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "215           0.971831           0.985915         0.974178        0.008783   \n",
       "195           0.978873           0.978873         0.974178        0.006640   \n",
       "207           0.978873           0.978873         0.974178        0.006640   \n",
       "263           0.971831           0.992958         0.974178        0.014470   \n",
       "289           0.971831           0.985915         0.974178        0.008783   \n",
       "..                 ...                ...              ...             ...   \n",
       "19            0.626761           0.626761         0.626761        0.000000   \n",
       "45            0.626761           0.626761         0.626761        0.000000   \n",
       "17            0.626761           0.626761         0.626761        0.000000   \n",
       "48            0.626761           0.626761         0.626761        0.000000   \n",
       "0             0.626761           0.626761         0.626761        0.000000   \n",
       "\n",
       "     rank_test_score  \n",
       "215                1  \n",
       "195                1  \n",
       "207                1  \n",
       "263                1  \n",
       "289                1  \n",
       "..               ...  \n",
       "19               277  \n",
       "45               277  \n",
       "17               277  \n",
       "48               277  \n",
       "0                277  \n",
       "\n",
       "[300 rows x 15 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame(gs.cv_results_)\n",
    "result_df.sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9440559440559441"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test = gs.predict(X_test)\n",
    "accuracy_score(y_test, pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 1.33549096e-03, 4.94494698e-03, 0.00000000e+00,\n",
       "       3.97585690e-06, 9.34141518e-02, 6.51982210e-03, 7.02625571e-02,\n",
       "       1.20680063e-01, 8.13146442e-03, 1.05668682e-03, 1.65773029e-02,\n",
       "       0.00000000e+00, 4.81324605e-03, 9.02874999e-03, 3.78019977e-05,\n",
       "       2.79283962e-04, 0.00000000e+00, 1.49012865e-01, 3.10905613e-05,\n",
       "       2.23908297e-01, 2.81342931e-02, 4.66786793e-02, 1.83046772e-03,\n",
       "       6.69333072e-03, 7.19996363e-06, 4.34145107e-03, 4.09313717e-02,\n",
       "       8.70474544e-02, 7.42979558e-02])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gs.best_estimator_\n",
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost(Extra Gradient Boost)\n",
    "- https://xgboost.readthedocs.io/\n",
    "- Gradient Boost 알고리즘을 기반으로 개선해서 나온 모델.\n",
    "- 캐글 경진대회에서 상위에 입상한 데이터 과학자들이 사용한 것으로 알려저 유명해짐\n",
    "- Gradient Boost의 단점인 느린수행시간을 해결하고 과적합을 제어할 수 있는 규제를 제공해 성능 높임\n",
    "- 두가지 개발 방법\n",
    "    - [Scikit-learn 래퍼 XGBoost 모듈 사용](https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn)\n",
    "    - [파이썬 래퍼 XGBoost 모듈 사용](https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.training)\n",
    "- 설치   \n",
    "``\n",
    "pip install xgboost\n",
    "conda install -y -c anaconda py-xgboost\n",
    "``\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\jiyoon\\anaconda3\\envs\\ml\\lib\\site-packages (0.90)\n",
      "Requirement already satisfied: scipy in c:\\users\\jiyoon\\anaconda3\\envs\\ml\\lib\\site-packages (from xgboost) (1.6.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\jiyoon\\anaconda3\\envs\\ml\\lib\\site-packages (from xgboost) (1.20.1)\n"
     ]
    }
   ],
   "source": [
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn 래퍼 XGBoost\n",
    "- XGBoost를 Scikit-learn프레임워크와 연동할 수 있도록 개발됨.\n",
    "- Scikit-learn의 Estimator들과 동일한 패턴으로 코드를 작성할 수 있다.\n",
    "- GridSearchCV나 Pipeline 등 Scikit-learn이 제공하는 다양한 유틸리티들을 사용할 수 있다.\n",
    "- XGBClassifier: 분류\n",
    "- XGBRegressor : 회귀 \n",
    "\n",
    "### 주요 매개변수\n",
    "- learning_rate : 학습률, 보통 0.01 ~ 0.2 사이의 값 사용\n",
    "- n_estimators : week tree 개수\n",
    "- max_depth: 트리의 depth 지정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(n_estimators = 200,\n",
    "                    learning_rate = 0.5,\n",
    "                    max_depth = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(learning_rate=0.5, max_depth=2, n_estimators=200)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = xgb.predict(X_train)\n",
    "pred_test = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.965034965034965)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, pred_train), accuracy_score(y_test, pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0000000e+00, 1.7377844e-02, 0.0000000e+00, 2.7057502e-02,\n",
       "       9.4335829e-04, 5.7103140e-03, 3.3941608e-02, 9.9188931e-02,\n",
       "       4.1985163e-03, 2.1932845e-03, 0.0000000e+00, 3.3285678e-04,\n",
       "       1.7986957e-02, 1.1520459e-02, 0.0000000e+00, 2.2246058e-03,\n",
       "       0.0000000e+00, 1.2838596e-03, 9.7346597e-04, 8.4046111e-04,\n",
       "       2.2470552e-01, 1.2404799e-02, 1.2866795e-01, 4.5809176e-02,\n",
       "       4.1861958e-03, 1.6558268e-04, 1.2857459e-02, 3.3936533e-01,\n",
       "       4.8814113e-03, 1.1825919e-03], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature importance\n",
    "fi = xgb.feature_importances_\n",
    "fi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
